{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11126425,"sourceType":"datasetVersion","datasetId":6938910},{"sourceId":11150864,"sourceType":"datasetVersion","datasetId":6956921},{"sourceId":11160659,"sourceType":"datasetVersion","datasetId":6963996},{"sourceId":11160884,"sourceType":"datasetVersion","datasetId":6779454},{"sourceId":11176088,"sourceType":"datasetVersion","datasetId":6975364},{"sourceId":90869,"sourceType":"modelInstanceVersion","modelInstanceId":76178,"modelId":100857},{"sourceId":301365,"sourceType":"modelInstanceVersion","modelInstanceId":257385,"modelId":278686}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ckapelonis02/sam2-fine-tune.git\n%cd /kaggle/working/sam2-fine-tune","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install -e .","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\npath = kagglehub.model_download(\"metaresearch/segment-anything-2/pyTorch/sam2-hiera-tiny\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import hydra\nimport numpy as np\nimport torch\nimport cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\nfrom sam2.build_sam import build_sam2\nfrom sam2.sam2_image_predictor import SAM2ImagePredictor\nfrom sam2.train_helper import read_batch\nfrom sam2.train_helper import read_dataset\nfrom sam2.train_helper import visualize_entry\nfrom sam2.train_helper import cleanup\n\ncleanup()\n\n# Configurations\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nhydra.core.global_hydra.GlobalHydra.instance().clear()\nhydra.initialize_config_module('sam2', version_base='1.2')\n\nsam2_model = build_sam2(\n    config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n    ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n    device=\"cuda\",\n    apply_postprocessing=False\n)\n\npredictor = SAM2ImagePredictor(sam2_model)\npredictor.model.sam_mask_decoder.train(True)\npredictor.model.sam_prompt_encoder.train(True)\noptimizer = torch.optim.AdamW(\n    params=predictor.model.parameters(),\n    lr=1e-5,\n    weight_decay=4e-5\n)\n\nscaler = torch.cuda.amp.GradScaler()\n\n# with open(\"/kaggle/input/data-2k-cropped/sorted_ancient.txt\", \"r\") as file:\n#     file_names = [int(line.strip()) for line in file]\n\ndata_size = 128\nfile_names = [i+1 for i in range(data_size)]\ntop_files = file_names[:data_size]\n\nrandom.shuffle(top_files)\n\ndata_dict = read_dataset(\n    images_path=\"/kaggle/input/real-data-128/images_final\",\n    masks_path=\"/kaggle/working/sam2-fine-tune/inverted\",\n    file_names=top_files\n)\n\nmean_iou = 0\nmax_masks = 150\nepochs = 10\nfor itr in range(data_size * epochs):\n    with torch.cuda.amp.autocast():\n        image, masks, input_point, input_label = read_batch(data_dict, itr % data_size, max_masks)\n        if (masks.shape[0] == 0):\n            continue\n        # visualize_entry(image, masks, input_point)\n\n        # Segment the image using SAM\n        predictor.set_image(image)  # apply SAM image encoder to the image\n\n        # Prompt encoding\n        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n            input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n            )\n        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n            points=(unnorm_coords, labels), boxes=None, masks=None\n            )\n\n        # Mask decoder\n        batched_mode = unnorm_coords.shape[0] > 1  # multi object prediction\n        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n            image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n            sparse_prompt_embeddings=sparse_embeddings,\n            dense_prompt_embeddings=dense_embeddings,\n            multimask_output=True,\n            repeat_image=batched_mode,\n            high_res_features=high_res_features\n            )\n\n        # Upscale the masks to the original image resolution\n        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n\n        # Segmentation Loss calculation\n        gt_mask = torch.tensor((masks / 255).astype(np.float32)).cuda()\n        prd_mask = torch.sigmoid(prd_masks[:, 0])  # Turn logit map to probability map\n        seg_loss = (-gt_mask * torch.log(prd_mask + 0.00001) - (1 - gt_mask) * torch.log((1 - prd_mask) + 0.00001)).mean()\n\n        # Score loss calculation (intersection over union) IoU\n        inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n        iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n        loss = seg_loss + score_loss * 0.05  # mix losses\n\n        # Backpropagation\n        predictor.model.zero_grad()  # empty gradient\n        scaler.scale(loss).backward()  # Backpropagate\n        scaler.step(optimizer)\n        scaler.update()  # Mix precision\n\n        if (itr % 500 == 0):\n            torch.save(predictor.model.state_dict(), f\"model{itr}.torch\")\n            print(\"Saved model.\")\n\n        mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n        if (itr % 100 == 0):\n            print(f\"step {itr} Accuracy (IoU) = {mean_iou}\")\n\n        # visualize_training_results(image, masks, prd_masks, mean_iou, itr)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/sam2-fine-tune/results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport cv2\nimport hydra\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom PIL import Image\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\nfrom sam2.test_helper import test_generator\nfrom sam2.train_helper import cleanup\n\ncleanup()\n\n# Configurations\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nhydra.core.global_hydra.GlobalHydra.instance().clear()\nhydra.initialize_config_module('sam2', version_base='1.2')\n\nsam2_model = build_sam2(\n    config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n    ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n    device=\"cuda\",\n    apply_postprocessing=False\n)\n\nmask_generator = SAM2AutomaticMaskGenerator(\n    model=sam2_model,\n    points_per_side=128,\n    points_per_batch=32,\n    pred_iou_thresh=0.7,\n    stability_score_thresh=0.88,\n    stability_score_offset=1.0,\n    mask_threshold=0.0,\n    box_nms_thresh=0.7,\n    crop_n_layers=2,\n    crop_nms_thresh=0.7,\n    # crop_overlap_ratio=0.5,\n    crop_n_points_downscale_factor=2,\n    # point_grids=None,\n    min_mask_region_area=25.0,\n    # output_mode=\"binary_mask\",\n    use_m2m=False,\n    # multimask_output=True,\n    # load_model=\"/kaggle/input/ancient-model-2k-cropped/pytorch/default/1/model3500ancient_2k_cropped.torch\"\n)\n\nstart_time = time.time()\ntest_generator(\n    mask_generator=mask_generator,\n    img_path=\"/kaggle/input/mosaic-images/butterfly.jpg\",\n    output_path=f\"/kaggle/working/sam2-fine-tune/results/masks_{time.time()}.png\",\n    rows=1,\n    cols=1,\n    max_mask_crop_region=0.1,\n    show_masks=True\n)\nprint(f\"Time taken: {time.time() - start_time}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install optuna\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport time\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\nfrom sam2.test_helper import test_generator\nfrom evaluate import *\n\n# Hyperparameter optimization using Bayesian Optimization\ndef objective(trial):\n    # Sample hyperparameters from the search space\n    points_per_side = 128\n    points_per_batch = 32\n    pred_iou_thresh = trial.suggest_float('pred_iou_thresh', 0.5, 0.9)\n    stability_score_thresh = trial.suggest_float('stability_score_thresh', 0.7, 0.95)\n    stability_score_offset = trial.suggest_float('stability_score_offset', 0.7, 1.2)\n    mask_threshold = trial.suggest_float('mask_threshold', 0.0, 0.6)\n    box_nms_thresh = 0.7\n    crop_n_layers = 2\n    crop_nms_thresh = 0.7\n    crop_overlap_ratio = 0.3\n    crop_n_points_downscale_factor = 2\n    min_mask_region_area = 25.0\n    use_m2m = False\n\n    # Set up the model with the sampled hyperparameters\n    sam2_model = build_sam2(\n        config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n        ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n        device=\"cuda\",\n        apply_postprocessing=False\n    )\n\n    mask_generator = SAM2AutomaticMaskGenerator(\n        model=sam2_model,\n        points_per_side=points_per_side,\n        points_per_batch=points_per_batch,\n        pred_iou_thresh=pred_iou_thresh,\n        stability_score_thresh=stability_score_thresh,\n        stability_score_offset=stability_score_offset,\n        mask_threshold=mask_threshold,\n        box_nms_thresh=box_nms_thresh,\n        crop_n_layers=crop_n_layers,\n        crop_nms_thresh=crop_nms_thresh,\n        crop_overlap_ratio=crop_overlap_ratio,\n        crop_n_points_downscale_factor=crop_n_points_downscale_factor,\n        min_mask_region_area=min_mask_region_area,\n        use_m2m=use_m2m\n    )\n\n    # Run the model and evaluate with your metrics function\n    img_path = \"/kaggle/input/evaluation-dataset/images_set/butterfly.jpg\"\n    output_path = \"/kaggle/working/sam2-fine-tune/results/butterfly.png\"\n\n    start_time = time.time()\n    test_generator(\n        mask_generator=mask_generator,\n        img_path=img_path,\n        output_path=output_path,\n        rows=1,\n        cols=1,\n        max_mask_crop_region=0.1,\n        show_masks=False\n    )\n    print(f\"Test run took {time.time() - start_time} seconds\")\n\n    # Use your metrics function here to calculate the IoU (or any other metric)\n    gt, pred = read_masks(\"/kaggle/input/evaluation-dataset/masks_set/butterfly.png\", output_path)\n    metrics = evaluate_pred(gt, pred)  # Assuming you have this function\n    iou_score = metrics['IoU']  # Example: IoU score\n\n    return iou_score  # Return the IoU as the objective function to maximize\n\n# Example: Use Optuna to perform Bayesian Optimization\nstudy = optuna.create_study(direction=\"maximize\")  # 'maximize' since we want to maximize IoU\nstudy.optimize(objective, n_trials=20)  # Number of trials to run\n\n# Get the best hyperparameters and the best score\nprint(\"Best Hyperparameters:\", study.best_params)\nprint(\"Best IoU Score:\", study.best_value)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T16:28:56.071757Z","iopub.execute_input":"2025-03-26T16:28:56.072049Z"}},"outputs":[{"name":"stderr","text":"[I 2025-03-26 16:28:56,077] A new study created in memory with name: no-name-f36d6655-90b7-46da-b395-56993241e75b\n","output_type":"stream"},{"name":"stdout","text":"Processing 1 of 1\n1861 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:32:15,662] Trial 0 finished with value: 0.94 and parameters: {'pred_iou_thresh': 0.7701764472168076, 'stability_score_thresh': 0.9195053653804519, 'stability_score_offset': 0.7873863652006368, 'mask_threshold': 0.2545665866945082}. Best is trial 0 with value: 0.94.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 198.76357698440552 seconds\nProcessing 1 of 1\n2328 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:35:47,378] Trial 1 finished with value: 0.914 and parameters: {'pred_iou_thresh': 0.5916063441187859, 'stability_score_thresh': 0.752410173944368, 'stability_score_offset': 1.0745639640562423, 'mask_threshold': 0.1012628398893242}. Best is trial 0 with value: 0.94.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 210.9339189529419 seconds\nProcessing 1 of 1\n2572 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:39:21,907] Trial 2 finished with value: 0.868 and parameters: {'pred_iou_thresh': 0.5265245145322136, 'stability_score_thresh': 0.7096591671018168, 'stability_score_offset': 0.9601039633893467, 'mask_threshold': 0.5740862281086649}. Best is trial 0 with value: 0.94.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 213.8806402683258 seconds\nProcessing 1 of 1\n2411 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:42:52,183] Trial 3 finished with value: 0.906 and parameters: {'pred_iou_thresh': 0.5483758716429645, 'stability_score_thresh': 0.768688191433413, 'stability_score_offset': 0.9273714394962258, 'mask_threshold': 0.5806184031358964}. Best is trial 0 with value: 0.94.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 209.63797640800476 seconds\nProcessing 1 of 1\n1810 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:46:10,072] Trial 4 finished with value: 0.943 and parameters: {'pred_iou_thresh': 0.7467155072206236, 'stability_score_thresh': 0.927620940299105, 'stability_score_offset': 0.9176923697930055, 'mask_threshold': 0.40962544501462417}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 197.254376411438 seconds\nProcessing 1 of 1\n1926 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:49:28,878] Trial 5 finished with value: 0.934 and parameters: {'pred_iou_thresh': 0.8155265038661501, 'stability_score_thresh': 0.7995016710168169, 'stability_score_offset': 1.0660359342025623, 'mask_threshold': 0.12795675378904883}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 198.17264223098755 seconds\nProcessing 1 of 1\n1933 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:52:48,394] Trial 6 finished with value: 0.935 and parameters: {'pred_iou_thresh': 0.8039072283559566, 'stability_score_thresh': 0.8288776310084137, 'stability_score_offset': 0.9621058808445495, 'mask_threshold': 0.33484133596334326}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 198.7157633304596 seconds\nProcessing 1 of 1\n1980 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:56:11,097] Trial 7 finished with value: 0.934 and parameters: {'pred_iou_thresh': 0.6735528186033698, 'stability_score_thresh': 0.8537786659419957, 'stability_score_offset': 1.1267202192387926, 'mask_threshold': 0.2718032845741301}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 201.9125382900238 seconds\nProcessing 1 of 1\n1986 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 16:59:34,856] Trial 8 finished with value: 0.933 and parameters: {'pred_iou_thresh': 0.5315011894960423, 'stability_score_thresh': 0.9258735488846309, 'stability_score_offset': 0.7143012737426908, 'mask_threshold': 0.08978692148500318}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 202.97058749198914 seconds\nProcessing 1 of 1\n2066 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 17:02:58,055] Trial 9 finished with value: 0.933 and parameters: {'pred_iou_thresh': 0.747879942377363, 'stability_score_thresh': 0.7889945858826082, 'stability_score_offset': 0.842475454013801, 'mask_threshold': 0.433435527557335}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 202.55713057518005 seconds\nProcessing 1 of 1\n1775 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 17:06:12,860] Trial 10 finished with value: 0.937 and parameters: {'pred_iou_thresh': 0.8706528575203315, 'stability_score_thresh': 0.8773481888588376, 'stability_score_offset': 1.182364167815913, 'mask_threshold': 0.4422149529318393}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 194.1377341747284 seconds\nProcessing 1 of 1\n1812 masks found\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-03-26 17:09:32,085] Trial 11 finished with value: 0.942 and parameters: {'pred_iou_thresh': 0.6843746051872427, 'stability_score_thresh': 0.9414298230112895, 'stability_score_offset': 0.7725378413309506, 'mask_threshold': 0.2764547643376969}. Best is trial 4 with value: 0.943.\n","output_type":"stream"},{"name":"stdout","text":"Final stitched segmentation saved as /kaggle/working/sam2-fine-tune/results/butterfly.png\nTest run took 198.55978441238403 seconds\nProcessing 1 of 1\n","output_type":"stream"}],"execution_count":null}]}