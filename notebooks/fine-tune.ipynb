{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11126425,"sourceType":"datasetVersion","datasetId":6938910},{"sourceId":11150864,"sourceType":"datasetVersion","datasetId":6956921},{"sourceId":11160659,"sourceType":"datasetVersion","datasetId":6963996},{"sourceId":11160884,"sourceType":"datasetVersion","datasetId":6779454},{"sourceId":11177421,"sourceType":"datasetVersion","datasetId":6975364},{"sourceId":11196462,"sourceType":"datasetVersion","datasetId":6990225},{"sourceId":90869,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":76178,"modelId":100857},{"sourceId":301325,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":257352,"modelId":278653},{"sourceId":301365,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":257385,"modelId":278686},{"sourceId":304858,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":260147,"modelId":281307}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ckapelonis02/sam2-fine-tune.git\n%cd /kaggle/working/sam2-fine-tune","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-28T12:35:22.577491Z","iopub.execute_input":"2025-03-28T12:35:22.577959Z","iopub.status.idle":"2025-03-28T12:35:28.340897Z","shell.execute_reply.started":"2025-03-28T12:35:22.577923Z","shell.execute_reply":"2025-03-28T12:35:28.339775Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'sam2-fine-tune'...\nremote: Enumerating objects: 366, done.\u001b[K\nremote: Counting objects: 100% (82/82), done.\u001b[K\nremote: Compressing objects: 100% (59/59), done.\u001b[K\nremote: Total 366 (delta 46), reused 57 (delta 23), pack-reused 284 (from 1)\u001b[K\nReceiving objects: 100% (366/366), 83.00 MiB | 21.69 MiB/s, done.\nResolving deltas: 100% (52/52), done.\n/kaggle/working/sam2-fine-tune\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%pip install -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T12:35:38.302033Z","iopub.execute_input":"2025-03-28T12:35:38.302403Z"}},"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/sam2-fine-tune\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from SAM-2==1.0) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from SAM-2==1.0) (0.20.1+cu121)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from SAM-2==1.0) (1.26.4)\nRequirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from SAM-2==1.0) (4.67.1)\nCollecting hydra-core>=1.3.2 (from SAM-2==1.0)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting iopath>=0.1.10 (from SAM-2==1.0)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from SAM-2==1.0) (11.0.0)\nRequirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\nCollecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.24.4->SAM-2==1.0) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.1->SAM-2==1.0) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.1->SAM-2==1.0) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.1->SAM-2==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.1->SAM-2==1.0) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.1->SAM-2==1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.1->SAM-2==1.0) (1.3.0)\nRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.1->SAM-2==1.0) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->SAM-2==1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.24.4->SAM-2==1.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->SAM-2==1.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.24.4->SAM-2==1.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.24.4->SAM-2==1.0) (2024.2.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: SAM-2, iopath\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import kagglehub\npath = kagglehub.model_download(\"metaresearch/segment-anything-2/pyTorch/sam2-hiera-tiny\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nfrom sam2.build_sam import build_sam2\nfrom sam2.sam2_image_predictor import SAM2ImagePredictor\nfrom sam2.train_helper import *\n\ncleanup()\n\n# Model Initialization\nsam2_model = build_sam2(\n    config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n    ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n    device=\"cuda\",\n    apply_postprocessing=False\n)\npredictor = SAM2ImagePredictor(sam2_model)\npredictor.model.sam_mask_decoder.train(True)\npredictor.model.sam_prompt_encoder.train(True)\n\n# Optimizer & Scheduler\noptimizer = optim.AdamW(predictor.model.parameters(), lr=1e-5, weight_decay=4e-5)\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10000, eta_min=1e-7)\nscaler = torch.cuda.amp.GradScaler()\n\n# Dataset Configuration\ndata_size = 2000\nfile_names = list(range(1, data_size + 1))\ntrain_size = int(0.8 * data_size)\ntrain_files, val_files = file_names[:train_size], file_names[train_size:]\n\ntrain_data = read_dataset(\"/kaggle/input/2k-hd-cropped/i\", \"/kaggle/input/2k-hd-cropped/m\", train_files)\nval_data = read_dataset(\"/kaggle/input/2k-hd-cropped/i\", \"/kaggle/input/2k-hd-cropped/m\", val_files)\n\n# Training Parameters\nmax_masks = 150\nepochs = 10\nbest_val_iou = 0.0\ngradient_accumulation_steps = 4\npatience = 3  # Number of epochs to wait before early stopping\nno_improvement_count = 0  # Counter for no improvement in validation IoU\n\n# Training Loop\nfor epoch in range(epochs):\n    total_iou = 0\n    total_loss = 0\n    random.shuffle(train_files)\n    \n    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n\n    for itr in tqdm(range(train_size), desc=\"Training Progress\"):\n        with torch.cuda.amp.autocast():\n            image, masks, input_point, input_label = read_batch(train_data, itr % train_size, max_masks)\n            prd_mask, prd_scores, gt_mask = process_batch(predictor, image, masks, input_point, input_label)\n\n            if prd_mask is None:\n                continue\n\n            iou, loss = compute_iou_loss(prd_mask, prd_scores, gt_mask)\n            loss = loss / gradient_accumulation_steps\n\n            scaler.scale(loss).backward()\n\n            if (itr + 1) % gradient_accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                predictor.model.zero_grad()\n\n            scheduler.step()\n            total_iou += iou.mean().item()\n            total_loss += loss.item()\n\n    mean_iou = total_iou / train_size\n    mean_loss = total_loss / train_size\n\n    val_iou = evaluate(predictor, val_data, val_files, max_masks)\n    print(f\"Epoch {epoch+1}: Train IoU = {mean_iou:.4f}, Train Loss = {mean_loss:.4f}, Val IoU = {val_iou:.4f}\")\n\n    if val_iou > best_val_iou:\n        best_val_iou = val_iou\n        torch.save(predictor.model.state_dict(), \"best_model.torch\")\n        print(f\"New best model saved, Val IoU = {best_val_iou:.4f}\")\n        no_improvement_count = 0  # Reset counter when improvement is seen\n    else:\n        no_improvement_count += 1\n        print(f\"No improvement in validation IoU for {no_improvement_count} epochs.\")\n\n    # Early stopping check\n    if no_improvement_count >= patience:\n        print(f\"Early stopping triggered. No improvement in validation IoU for {patience} consecutive epochs.\")\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/sam2-fine-tune/results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport cv2\nimport hydra\nimport matplotlib.pyplot as plt\nimport os\nimport time\nfrom PIL import Image\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\nfrom sam2.test_helper import test_generator\nfrom sam2.train_helper import cleanup\n\ncleanup()\n\n# Configurations\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nhydra.core.global_hydra.GlobalHydra.instance().clear()\nhydra.initialize_config_module('sam2', version_base='1.2')\n\nsam2_model = build_sam2(\n    config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n    ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n    device=\"cuda\",\n    apply_postprocessing=False\n)\n\nmask_generator = SAM2AutomaticMaskGenerator(\n    model=sam2_model,\n    points_per_side=32,\n    points_per_batch=4,\n    pred_iou_thresh=0.75,\n    stability_score_thresh=0.92,\n    stability_score_offset=0.91,\n    mask_threshold=0.4,\n    box_nms_thresh=0.7,\n    crop_n_layers=2,\n    crop_nms_thresh=0.7,\n    crop_overlap_ratio=0.3,\n    crop_n_points_downscale_factor=2,\n    point_grids=None,\n    min_mask_region_area=25.0,\n    output_mode=\"binary_mask\",\n    use_m2m=False,\n    multimask_output=True,\n    load_model=\"/kaggle/input/trained-with-epochs/pytorch/default/1/best_model.torch\"\n)\n\nimport pandas as pd\n\n# Read the CSV file\ndf = pd.read_csv(\"/kaggle/input/temp-csv/crops.csv\")  # Replace with your actual file path\n\n# Access specific columns\nfile_names = df[\"file_name\"]\nrows = df[\"rows\"]\ncols = df[\"cols\"]\n\n# Example: Iterate over the data\nfor file_name, row, col in zip(file_names, rows, cols):\n    print(f\"File: {file_name}, Rows: {row}, Cols: {col}\")\n    start_time = time.time()\n    test_generator(\n        mask_generator=mask_generator,\n        img_path=f\"/kaggle/input/evaluation-dataset/evaluation_dataset/images_set/{file_name}.jpg\",\n        output_path=f\"/kaggle/working/sam2-fine-tune/results/{file_name}.png\",\n        rows=row,\n        cols=col,\n        max_mask_crop_region=0.1,\n        show_masks=False\n    )\n    print(f\"Time taken: {time.time() - start_time}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nimport numpy as np\nimport time\nfrom sam2.build_sam import build_sam2\nfrom sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\nfrom sam2.test_helper import test_generator\nfrom evaluate import *\n\ndef objective(trial):\n    points_per_side = 128\n    points_per_batch = 32\n    pred_iou_thresh = trial.suggest_float('pred_iou_thresh', 0.5, 0.9)\n    stability_score_thresh = trial.suggest_float('stability_score_thresh', 0.7, 0.95)\n    stability_score_offset = trial.suggest_float('stability_score_offset', 0.7, 1.2)\n    mask_threshold = trial.suggest_float('mask_threshold', 0.0, 0.6)\n    box_nms_thresh = 0.7\n    crop_n_layers = 2\n    crop_nms_thresh = 0.7\n    crop_overlap_ratio = 0.3\n    crop_n_points_downscale_factor = 2\n    min_mask_region_area = 25.0\n    use_m2m = False\n\n    sam2_model = build_sam2(\n        config_file=\"../sam2_configs/sam2_hiera_t.yaml\",\n        ckpt_path=\"/kaggle/input/segment-anything-2/pytorch/sam2-hiera-tiny/1/sam2_hiera_tiny.pt\",\n        device=\"cuda\",\n        apply_postprocessing=False\n    )\n\n    mask_generator = SAM2AutomaticMaskGenerator(\n        model=sam2_model,\n        points_per_side=points_per_side,\n        points_per_batch=points_per_batch,\n        pred_iou_thresh=pred_iou_thresh,\n        stability_score_thresh=stability_score_thresh,\n        stability_score_offset=stability_score_offset,\n        mask_threshold=mask_threshold,\n        box_nms_thresh=box_nms_thresh,\n        crop_n_layers=crop_n_layers,\n        crop_nms_thresh=crop_nms_thresh,\n        crop_overlap_ratio=crop_overlap_ratio,\n        crop_n_points_downscale_factor=crop_n_points_downscale_factor,\n        min_mask_region_area=min_mask_region_area,\n        use_m2m=use_m2m\n    )\n\n    img_path = \"/kaggle/input/evaluation-dataset/images_set/butterfly.jpg\"\n    output_path = \"/kaggle/working/sam2-fine-tune/results/butterfly.png\"\n\n    start_time = time.time()\n    test_generator(\n        mask_generator=mask_generator,\n        img_path=img_path,\n        output_path=output_path,\n        rows=1,\n        cols=1,\n        max_mask_crop_region=0.1,\n        show_masks=False\n    )\n    print(f\"Test run took {time.time() - start_time} seconds\")\n\n    gt, pred = read_masks(\"/kaggle/input/evaluation-dataset/masks_set/butterfly.png\", output_path)\n    metrics = evaluate_pred(gt, pred)\n    iou_score = metrics['IoU']\n\n    return iou_score\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=20)\n\nprint(\"Best Hyperparameters:\", study.best_params)\nprint(\"Best IoU Score:\", study.best_value)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}